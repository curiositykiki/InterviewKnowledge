### 为什么需要消息中间件？

消息中间件的枚举：rabbitMQ、activeMQ、zeroMQ、rocketMQ、Kafka、redis

消息中间件的应用场景：

`非实时性`：当不需要立即获得结果，但是并发量又需要进行控制的时候，差不多就是需要使用消息队列的时候。主要解决了**应用耦合、异步处理、流量削锋**等问题。

`应用耦合`：多应用间通过消息队列对同一消息进行处理，避免调用接口失败导致整个过程失败；（如：订单->库存）

`异步处理`：多应用对消息队列中同一消息进行处理，应用间并发处理消息，相比串行处理，减少处理时间；(点对多场景，广播场景(注册发短信，发邮件)等等)

`限流削峰`：应用于秒杀或抢购活动中，避免流量过大导致应用系统挂掉的情况；(根据服务承受度设置队列大小，超过了就返回活动结束了，咱们经常各大商城秒杀，心里还没有点B数吗)减少压力,避免服务挂掉。

`消息驱动的系统`：系统分为消息队列、消息生产者、消息消费者，生产者负责产生消息，消费者(可能有多个)负责对消息进行处理；(分工处理(各自对应相应的队列)，灵活应用(收到就处理/定时处理))

**同时，消息队列是异步RPC的主要手段之一；**



两种工作模式：

`点对点`：每个消息只有一个消费者（Consumer），不可重复消费(一旦被消费，消息就不再在消息队列中)

`发布/订阅`：微信公众号(Topic)，大伙(订阅者)订阅关注之后，微信公众号运营平台(发布者)发布信息后，大伙微信就都收到信息了，这里其实还分pull/push的。一个是主动推送，一个是被动拉取

公司日常中最常用的就是kafka，这里着重介绍kafka



### 功能：

**`功能`**：这个就多了，优先级队列、延迟队列(划分不同的延迟队列来避免重新排序消耗性能，缺点嘛自己悟)、死信队列(放没有推送成功的)、消费模式(pull/push)、广播消费、消息回溯(可追溯嘛，不然被卖了都不知道是谁)、消息堆积+持久化、消息追踪(链路条，方便定位)、消息过滤(根据规则过滤啊，不同类别消息发送到不同topic)、多协议支持(通用性)、跨语言支持(流行程度)、流量控制(嘿嘿嘿，上面有)、消息顺序性(还要再说一遍？)、安全机制(身份认证，权限认证(读写))、消息幂等性(承诺知道不，答应人家的事就一定要做到)、事务性消息(不想说)等

**`性能`**：一般是指其吞吐量(统一大小的消息体和不同大小的消息体生产和消耗能力)，性能和功能很多时候是相悖的，鱼和熊掌不可兼得。

**`高可靠、高可用`**：先说可靠，主要在于消息的持久化这一块(消息只要写入就一定会被消费，不会因为故障导致数据丢失(这个就很好测试出来了吧))。如果是从系统的角度来看就得从整体的维度去衡量了(不能单单只靠消息中间件本身，要从生产端、服务端、消费端三个维度去保障)。
 再说可用，主要在于一个是对外部服务的依赖性(**像kafka依赖zookeeper**)，依赖也分强依赖和弱依赖，一个在于本身的备份机制所带来的保障性(像主从复制这种备份啊，增加多个slave来加强保障同时也会存在资源浪费，大部分时候Slave可能是空闲的)。

**`运维`**：通常有审核评估啊、监控啊、报警提醒啊、容灾啊、扩容啊、升级部署等等，一方面看中间件支撑的维度，一方面就看结合自动化运维的难易度

**`社区力度及生态发展`**：这个好理解吧，使用开源框架最开始基本上愉快的奔跑，但时不时的总会掉坑里，能不能爬出来一方面看自身的实力，一方面就看社区的力度了

**`成本`：** 尽量贴合团队自身的技术栈体系，让一个C栈的团队去深挖zeroMQ总比scala编写kafka要容易的多



1. kafka的框架模型：

   ![](img/kafka1.png)

   1. producer：一般情况下，一个消息会被发布到一个特定的主题上。生产者在默认情况下把消息均衡地分布到主题的所有分区上，而并不关心特定消息会被写到哪个分区。不过，在某些情况下，生产者会把消息直接写到指定的分区。**这通常是通过消息键和分区器来实现的，分区器为键生成一个散列值，并将其映射到指定的分区上。**这样可以保证包含同一个键的消息会被写到同一个分区上；
   2. consumer：消费者**订阅**一个或多个主题，并按照消息生成的顺序读取它们。消费者通过检查消息的偏移量来区分已经读取过的消息。偏移量是另一种元数据，它是一个不断递增的整数值，在创建消息时，Kafka会把它添加到消息里。**在给定的分区里，每个消息的偏移量都是唯一的。消费者把每个分区最后读取的消息偏移量保存在Zookeeper或Kafka上，如果消费者关闭或重启，它的读取状态不会丢失。**消费者一般有两种方式，带消费组和不带消费组。我们当前的应用场景建议大家都带消费组；
   3. broker：一个独立的Kafka服务器被称为broker。broker接收来自生产者的消息，**为消息设置偏移量**，并提交消息到**磁盘保存**。broker为消费者提供服务，对读取分区的请求作出响应，返回已经提交到磁盘上的消息；
   4. cluster：broker是集群的组成部分。每个集群都有一个broker同时充当了集群控制器的角色（自动从集群的活跃成员中选举出来）。控制器负责管理工作，包括将分区分配给broker和监控broker。在集群中，一个分区从属于一个broker，该broker被称为分区的首领。一个分区可以分配给多个broker，这个时候会发生分区复制。这种复制机制为分区提供了消息冗余，如果有一个broker失效，其他broker可以接管领导权。不过，相关的消费者和生产者都要重新连接到新的首领；

2. kafka的概念

   ![](img/kafka2.png)

   1. 话题topic：代表一类数据，可以认为是数据库里面的一个表；**可以通过topic将进入kafka的消息进行过滤，将其分入指定的topic；**
   2. 分区：一个分区就是一个提交日志。消息以追加的方式写入分区，然后以先入先出的顺序读取；

3. 生产者消费者的组合模型

   ![](img/kafka3.png)
   
4. 额外：

   1. zookeeper

      可以参考这边文章[什么是zookeeper](https://zhuanlan.zhihu.com/p/69114539?utm_source=wechat_session)

      简单来说，如果我们只有一个kafka集群，生产者把消息放在哪个主题哪个分区，消费者从哪个主题哪个分区哪个offset开始读取数据都是未知的；因此需要一个协调器去协调，这就是zookeeper。

   2. CAP理论：C：原子性、A：可用性、P：分区容错性；

      C是指数据在分布式环境下的多副本之间能否保持一致性，这里的一致性更多是指强一致性。zookeeper是AP的，也就是说，zookeeper为了保持高可用性有可能会出错，因此要求高可用但是允许失败的任务，例如RPC调用，可以使用zookeeper来解决；

      
