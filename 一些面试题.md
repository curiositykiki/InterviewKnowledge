### new和malloc的区别

1. 都是在堆上面分配内存，但是malloc**不具备初始化功能**，new**具备初始化功能**（其实new的底层实现还是malloc，但是会使用**构造函数**来进行初始化）；

2. malloc是一个**函数**，需要**显式指定需要分配的字节数**，返回值是**void\*无类型指针**，因此需要进行强制类型转换；new是**运算符**，只需要指定所需要的的内存的类型，所需要的的字节数会自动计算，返回值为**指定类型的指针**；

3. malloc分配内存失败会**返回空指针**，new分配内存失败会**返回bad_alloc异常**；

   注意：如果发生了bad_alloc，可以通过设置set_new_handler来进行处理：

   **std::set_new_handler(no_memory);**

   这样处理之后，如果new失败了，就会去执行no_memory函数；

4. malloc分配的内存用free来释放，new对应delete，new[]对应delete[]；

5. new支持重载，比如new（nothrow）失败会返回空指针，const new，new（buffer）在指定的位置分配内存，这个new（buffer）是在指定的buffer上分配，**如果这个buffer是栈，那生成的对象也是在栈上了**；

6. 使用new分配的内存，禁止使用memcpy和realloc等函数，因为这俩都是进行**内存值的拷贝**，也就是说，如果是指针，那只是把指针copy了，是一种**浅拷贝**；正确做法应该是调用构造函数创建新对象来进行**深拷贝**。



### 红黑树

1. 是一种**自平衡的二叉查找树**，同时不是完美的平衡二叉树，左右子树之差有可能超过1；

2. 性质：

   1. 根节点肯定是黑色的；
   2. 每个节点只能是红色或者黑色；
   3. 叶子节点（是指null）肯定是黑色的；
   4. 任意两个连续的节点不能都为红色；
   5. **任意一个节点到达每个叶子节点经过的黑色节点必然相等；**

3. 自平衡的操作：通过旋转和变色就可以了达到平衡。

   1. 左旋：以某个结点作为支点(旋转结点)，其右子结点变为旋转结点的父结点，右子结点的左子结点变为旋转结点的右子结点，左子结点保持不变。（跟平衡二叉树的旋转一样）
   2. 右旋：以某个结点作为支点(旋转结点)，其左子结点变为旋转结点的父结点，左子结点的右子结点变为旋转结点的左子结点，右子结点保持不变。
   3. 变色：结点的颜色由红变黑或由黑变红。

4. **红黑树查找**：跟二叉排序树一模一样，最坏时间复杂度为O（logn），此时刚好此次查找路径**红黑相间**。

5. **红黑树插入**：首先查找插入的位置，然后进行自平衡。

   1. 新节点插入是初始颜色为**红色**，所以最关键的就看父节点是什么颜色；
   2. **父节点为黑色**，直接插入；
   3. **父节点为红色，叔叔节点也是红色，**则将父节点和叔叔节点**设置为黑色**，祖父节点设置为**红色**，然后把祖父节点当做插入来看待，继续自平衡；
   4. **父节点为红色，叔叔节点是黑色或者不存在，且父节点是祖父节点的左节点，**由于父节点是红色的所以祖父节点必然是黑色的，进行**右旋**，同时注意，旋转后**祖父节点那个位置的节点还是黑色**的，然后**祖父节点那个位置的两个子节点都是红色**的；
   5. **父节点为红色，叔叔节点是黑色或者不存在，且父节点是祖父节点的右节点，**与上述情况类似，这个时候与平衡二叉树的LR相似，所以**先左旋后右旋**，结果跟4差不多；

6. **红黑树的删除**：首先查找要删除的节点，然后进行自平衡。

   1. 删除的节点**无子节点**，直接删除；

   2. 删除的节点**有一个子节点**，用子节点**替换**删除的节点；

   3. 删除的节点**有两个子节点**，用其**后驱（中序遍历的下一个，就是右子树的左下角那个节点）节点替换**删除节点；

      加上颜色特征：

      1. 替换节点是**红色**，将替代节点的值复制过去删除节点，**替代节点换成删除节点的颜色，**然后**递归**检查那个替代节点；
      2. 替换节点是**黑色**，且是**父节点的左子节点**，兄弟节点是**红色的**，



### topK问题（非常重要！！！）

给定1亿个数字，找出前100大的数字。

使用**堆排序**来解决，维护一个100个元素的**小顶堆**，这个堆的顶端就是这个100个元素的最小值。因此，只要将剩余的数字逐个与堆顶比较，**如果比堆顶大则将堆顶替换，然后调整堆。**直到最后就会剩余100个最大的元素。边插入边调整堆，复杂度为O（KlogK），然后剩余的N-K个点最坏情况下每次都要插入调整堆，时间复杂度为O（（N-K）logK），综上，总体时间复杂度为O（NlogK）。

代码：

```c++
#include<bits/stdc++.h>
using namespace std;
void fixheap(vector<int> &h) {
	int step = 0;
	while (step<h.size()/2) {
		int judge = 2 * step + 1;
		if (judge + 1 < h.size() && h[judge + 1] < h[judge])
			judge++;
		if (h[judge] > h[step])
			break;
		swap(h[step], h[judge]);
		step = judge;
	}
	return;
}
int main() {
	vector<int> wh{ 11,22,33,44,55,66,77,88,99,2,5,0,1,8,9,6,623 }, tempheap;
	int k = 5;
	for (int i = 0; i < k; ++i) {
		tempheap.push_back(wh[i]);
		fixheap(tempheap);
	}
	for (int i = k; i < wh.size(); ++i)
		if (wh[i] > tempheap[1]) {
			swap(wh[i], tempheap[0]);
			fixheap(tempheap);
		}
	for (int i = 0; i < k; ++i)
		cout << tempheap[i] << endl;//输出66 88 77 99 623
	return 0;
}
```

### topK问题（这里以找到第K大的数为例）有没有其他更好的解法？

**思路**：利用**快速排序的思想**，如果要找到第K大的数字，可以先把数组以mid划分为两半，一半小于等于array[mid]，一半大于array[mid]。①如果K<mid，说明**要寻找的K在左边**，只需要在左边中查找就ok；②如果K>mid，说明**要寻找的K在右边**，注意，此时要在右边寻找时，**由于已经确定了mid前的都是小于K的，所以在右边寻找K-mid大的数字**；注意了，快速排序的时间复杂度为O（nlogn），是通过**master定理计算的**，递归的快速排序为T（n）=2T（n/2）+f（n），f（n）是找到那个数的位置，以这个数分成两个T（n/2）。此外，选取基准可以通过**三数取中**的方法，即取头尾中间三个数作比较，用大小为中间的数作为基准来划分。

补充：**master定理**

![](img/master.jpg)

**代码**

```
#include<bits/stdc++.h>
#include<map>
#include<unordered_map>
#include<thread>
#include<mutex>
#include<Windows.h>
//#include"Bank.h"
using namespace std;
int oneSort(int l, int r, vector<int> &wh) {
	if (l >= r)
		return l;
	int judge = wh[l], index = l;
	while (l < r) {
		while (l < r&&wh[r] >= judge)
			r--;
		while (l < r&&wh[l] <= judge)
			l++;
		swap(wh[l], wh[r]);
	}
	wh[index] = wh[l];
	wh[l] = judge;
	return l;
}
int main() {
	vector<int> wh{ 11,22,33,44,55,66,77,88,99,2,5,0,1,8,9,6,623 };
	int k = 6, left = 0, right = wh.size() - 1;
	while (1) {
		int partition = oneSort(left, right, wh);
		if (partition == k - 1) {//找到第k大的时候输出
			cout << wh[partition] << endl;
			break;
		}
		if (partition < k)
			left = partition + 1;
		else
			right = partition - 1;
	}
	return 0;
}
```

https://www.jianshu.com/p/e136ec79235c



### 内存对齐问题

为什么要考虑内存对齐问题？

可执行程序是由一系列CPU指令构成的，对于一些指令是需要访问内存的，且CPU不是按位读取内存的，而是按双字节。如果内存没有对齐，CPU取得数据时必须按照偏移量去读取所需要的的数据所谓的地址；如果对齐了内存，就可以直接获取所需要的的数据。虽然CPU本身就可以读取未对齐的内存，但是性能上有可能会受到影响；有些CPU甚至会抛出异常，而且对于别的一些平台可能不可移植。

那么内存对齐包含什么内容呢？

首先应该知道的是，**系统的默认对齐系数**：linux默认为#pragma pack（4），windows默认为#pragma pack（8）；没错，我们可以用#pragma pack（n）来指定对齐系数的大小；

第二，就是**偏移量**：简单来说，在32位操作系统中，32位代表4字节，所以每一块4字节里面需要一个offset偏移量来指定这个数据在这一块里面的那个地址开始，32位操作系统自然就是0~31；

第三，就是**三个原则**：

1. 结构体或者共用体中第一个数据的偏移量为0，此后的**偏移量必须是#pragma pack（n）指定的n和那个数据长度较小的那个的倍数**；
2. 结构体或者共同体内部数据对齐完毕后，**整个结构体和共同体也要对齐**。标准为#pragma pack（n）指定的n和**结构体和共同体内最长数据的长度**中较小的一个；
3. 如果结构体嵌套了，那就是套娃了。我们可以把嵌套的那个共同体当做一个成员，然后**先按照规则2求出来它的起始偏移量**，然后根据规则2计算整体偏移量，最后下一个元素再根据1来正常做对齐；

例子：

#pragma pack（4）

struct X{

​	int a；//长度4字节，与#pragma pack（n）比较，较小的是4，因此**偏移量应该是4的倍数**，这里是0，满足要求；所以a放在0~3这四位里面；

​	char b；//长度1字节，与#pragma pack（n）比较，较小的是1，因此**偏移量应该是1的倍数**，这里是4（**其实就是已经被人占用的长度**），满足要求；所以a放在4~4这一位里面；

​	short c；//长度2字节，与#pragma pack（n）比较，较小的是2，因此**偏移量应该是2的倍数**，这里是5，不满足要求，对齐为6；所以a放在6~7这两位里面；

​	char d；//长度1字节，与#pragma pack（n）比较，较小的是1，因此**偏移量应该是1的倍数**，这里是8，满足要求；所以a放在8~8这两位里面；

}

因为占用了0~8这9位，所以这个结构体的长度是9字节。首先计算整体对齐系数 =min （max（int，char，short）**（结构体内最长的那个结构）**，4**（由#pragma pack（n）指定）**） = min（4，4） = 4，因此应该是4的倍数，应该对齐为12，所以这个结构体要占12字节的空间。



#pragma pack（8）

struct X{

​	int a；//长度4字节，与#pragma pack（n）比较，较小的是4，因此**偏移量应该是4的倍数**，这里是0，满足要求；所以a放在0~3这四位里面；

​	char b；//长度1字节，与#pragma pack（n）比较，较小的是1，因此**偏移量应该是1的倍数**，这里是4，满足要求；所以a放在4~4这一位里面；

​	short c；//长度2字节，与#pragma pack（n）比较，较小的是2，因此**偏移量应该是2的倍数**，这里是5，不满足要求，对齐为6；所以a放在6~7这两位里面；

​	**//首先按照原则1计算，结构体Y内部最长是int = 4位，目前默认是8，因此偏移量应该是4的倍数，这里是8，满足要求；**

​	struct Y{

​		int a1；//长度4字节，与#pragma pack（n）比较，较小的是4，因此**偏移量应该是4的倍数**，这里是8，满足要求；所以a放在8~11这四位里面；

​		char b1；//长度1字节，与#pragma pack（n）比较，较小的是1，因此**偏移量应该是1的倍数**，这里是12，满足要求；所以a放在12~12这一位里面；

​		short c1；//长度2字节，与#pragma pack（n）比较，较小的是2，因此**偏移量应该是2的倍数**，这里是13，不满足要求，对齐为14；所以a放在14~15这两位里面；

​		char d1；//长度1字节，与#pragma pack（n）比较，较小的是1，因此**偏移量应该是1的倍数**，这里是16，满足要求；所以a放在16~16这一位里面；

​	}

**//结构体Y内部最长为int = 4位，默认为8位，因此偏移量应该是4的倍数，这里是17，不满足要求，对齐为20，下一个元素从21开始；**

​	char d；//长度1字节，与#pragma pack（n）比较，较小的是1，因此**偏移量应该是1的倍数**，这里是21，满足要求；所以a放在21~21这一位里面；

}

跟上述的计算类似，这里结构体X内最大的为int = 4（struct Y不算），默认为8，所以偏移量应该为4的倍数，这里是22，不满足要求，因此对齐为24；



### char\*和char[]的区别

1. char\*是一个指针定义，char[]是一个数组定义。数组是一块连续的内存，所以可以通过sizeof求得整个字符串的长度，除以每个字符的长度可以得到字符串的长度；但是sizeof用于char\*只能得到指针的长度，并不能取得字符串的长度；
2. 第二个就是**分配的内存位置不同**。如果有初始化，char\*分配的是在常数区域**（一般内存区域分为5块：栈（一些局部变量等等）、堆（动态分配的内存）、静态存储区域（全局变量和static变量）、常量存储区域、自由存储区域）**的内存，因此初始化之后不能修改字符串的值；char[]分配的是栈上面的内存，因此可以改变字符串内部的值；
3. 第三个就是**读写的权限不同**。数组定义的数组名可以当作指向一块连续内存开头的地址，可以认为是一个指针。**但是只能是一个常数指针**，因为char[]初始化之后不能指向别的字符串，但是char\*可以指向别的数组；
4. 第四个就是**赋值的时刻不同**。因为指针定义指向一个常量字符串，所以**编译**的时候就已经分配了；数组定义的分配是需要等到**运行**时才会分配；
5. 第五个就是**存取效率不同。**在栈上面的读取比常数存储区域的读取要快，所以数组定义的字符串读取速度会比指针定义的字符串的读取速度快；



### 堆和栈有什么区别？

1. 第一个是**管理的方式不同**。栈是由编译器自动分配的，用于存储局部变量，而堆是程序员申请分配的。并且，堆和栈属于两块不同的存储区域。
2. 第二个是**增长方向不同**。栈是由高地址往低地址分配的，而堆是由低地址往高地址分配的，栈和堆是相对生长的（可以理解为栈和堆是三文治的两块面包，争夺中间的空间，**目的应该是为了节省内存，相对正常可以充分利用内存空间**）。**同时，栈的大小一般是固定的，大概是1-2Mb；堆的大小一般大很多。**（这个可以用来判断分配在堆还是栈）
3. 第三个是**分配的效率不同**。**栈是一块连续的内存，只要申请的大小小于栈剩余空间**，就分配内存；而堆是**不连续的内存空间，当申请堆的空间的时候，会遍历空闲内存链表**，找到第一块大于等于申请空间的内存块返回给程序，多余的那部分内存将添加回链表，释放的时候再放回链表上；因此，**栈上的分配比堆上的分配高效。**
4. 第四个是**碎片问题**。由于栈的按一定顺序分配和释放的，所以不会存在中间有内部碎片这样的问题，因为某个栈变量释放的时候，其前面的所有变量都会被释放；反观堆，因为是程序员通过new和delete控制的，所以可能会存在大量的碎片，造成分配效率降低。



### C++中有哪些段

1. 一般可以分为TEXT段，DATA段和BSS段；其中TEXT段是只读的，DATA和BSS都是可读写的；
2. TEXT存放程序二进制码，编译时确定；
3. DATA段包括了STACK、HEAP、STATIC段，存放程序运行过程中的局部变量、一些全局变量和静态变量动态分配的变量等；
4. BSS段是一个比较特殊的段，用于存放**未初始化的**全局变量、静态变量，这块区域会**自动置0**，所以未初始化的全局变量静态变量有初值0；



### C++中有哪些存储区域

1. 栈，用于存放局部变量，由编译器自助分配和回收，大小一般为1-2MB；
2. 堆，用于存放动态分配的变量，由程序员控制其分配和回收，大小没有限制，理论上可以达到4GB；如果没有主动回收内存，可能会造成**内存泄漏**，程序结束后会自动收回；
3. 静态存储区与，用于存放全局变量和静态变量；
4. 字符串常量区，用于存放字符串常量，程序结束后自动收回，这块区域是只读的；
5. 程序代码区，存放程序的二进制码，这个区域是只读的；



### C++中static关键字的作用

1. 第一个是**改变变量的生命周期。**一个**局部变量**如果用static修饰，那这个变量的生命周期就变为程序的生命周期，并且存储在全局数据区域，但是其**作用域**不会改变。
2. 第二个是**静态变量只会被初始化一次。**如果再次进行初始化不会产生任何效果，如果没有进行初始化，其值为0；
3. 第三个是**隐藏**。如果存在多个文件同时编译，A文件和B文件中的同名全局变量可能会发生冲突；如果用static修饰一个全局变量，则该变量的作用域变为文件内，在别的文件**即使使用extern也无法获取该变量**；
4. 第四个是**用于修饰类成员变量和类成员函数。**如果修饰了类成员变量或者类成员函数，则其将属于整个类，而不属于任何一个对象；同时，静态成员变量也是之初始化一次，静态成员函数**只能访问静态成员变量**。但是非静态成员可以随意访问静态成员；因为静态成员函数属于整个类，所以没有this指针，所以无法访问具体对象的非静态成员变量。此外，静态类成员变量的初始化必须在类外进行，一般就是在类实现文件中初始化。



### 进程和线程的区别？

1. 进程是操作系统**资源分配**的基本单位，而线程是**处理器调度**和执行的基本单位；

2. 每个进程都有**独立的代码和数据空间（程序上下文）**，一个进程内可以包含多个线程，这些线程共享代码和数据空间，**但是每个线程都有自己独立的运行栈和程序计数器（PC）**；因此，线程之间切换的开销小。程序之间的切换会有较大的开销；

3. 因为线程共享进程的资源，所以某个线程发生错误会导致整个进程终止；而两个进程之间是不会相互影响的；

4. 父和子进程使用进程间通信机制，同一进程的线程通过读取和写入数据到进程变量来通信。

   



### 10亿QQ号，如何找出重复的那一个？

1. 使用**hash+set的方法：**
   1. 首先将所有QQ号对500取模，这样所有QQ号会被分成500组，最重要的是**相同的QQ号肯定在同一组内；**
   2. 然后每一组分别建立一个set，然后遍历自己分组的数据，就能找到那个重复的QQ号；
2. 使用**bitmap位图法：**
   1. 首先我们知道位图可以用一位来表示该数据是否存在，在这里我们用一位来表示QQ号是否存在；因此，假设QQ号都为10位的情况下，QQ号的范围为[10亿，100亿)，也就是说一共90亿个数字，我们用90亿位来表示，90亿位相当于11.25亿字节（**10亿字节=1GB**），也就是总共需要1.125GB内存；
   2. 内存不够的情况下，我们依然选择分组，**这里根据QQ号的首位数字分为1-9共9组；**如果还是太大就根据第二位继续细分；
   3. 从QQ号小的开始用bitmap记录其状态；由于文件间的QQ号是有序的，所以如果1开头的QQ号检查完了，我们可以情况刚才的内存用来记录2开头的QQ号；



### 手写strcpy, strcat, strcmp, memcpy等函数

1. 手写strcpy

   char\* Strcpy(char \*a, const char \*b) {
   	if (a == NULL || b == NULL) {
   		cout << "bad argument." << endl;
   		return NULL;
   	}
   	char \*mark = a;
   	while ((\*a++ = \*b++) != '\0')
   		continue;
   	return mark;
   }

2. 手写strcat

   char\* Strcat(char \*a, const char \*b) {
   	if (a == NULL || b == NULL) {
   		cout << "bad argument." << endl;
   		return NULL;
   	}
   	char \*mark = a;
   	while (\*a != '\0') {
   		a++;
   	}
   	while ((\*a++ = \*b++) != '\0')
   		continue;
   	return mark;
   }

3. 手写strcmp

   int Strcmp(const char \*a, const char \*b) {
   	if (a == NULL || b == NULL) {
   		cout << "bad argument." << endl;
   		return a==NULL;
   	}
   	while (\*a == *b) {
   		if (\*a == '\0')
   			return 0;
   		a++, b++;
   	}
   	return \*a - \*b;
   }

4. 手写memcpy

   void\* Memcpy(void \*a, const void \*b,size_t n) {
   	char \*pa = (char\*)a, \*pb = (char\*)b;
   	if (pa > (pb + n) || pa < pb) {//这里表示a的地址与b的地址没有冲突
   		while (n--)
   			\*pa++ = \*pb++;
   	}
   	else {**//如果b的末尾有部分跟a开头重叠，就从末尾开始复制**
   		pa = (char\*)(pa + n - 1);
   		pb = (char\*)(pb + n - 1);
   		while (n--)
   			\*pa-- = \*pb--;
   	}
   	return a;
   }



### 10进制转16进制

注意10进制转换16进制就是不断除以16，记录余数；然后取商继续除以16，记录余数；直到商为0，这个时候把商逆序就是结果了；

string ten2dex(const string &ori) {
	int temp = stoi(ori),remainder;
	string ans;
	while (temp != 0) {
		remainder = temp % 16;
		temp /= 16;
		if (remainder < 10)
			ans = to_string(remainder) + ans;
		else
			ans = char(55+remainder) + ans;**//A的ASCII码是65，因为remainder要先-10，所以直接+55就ok**
	}
	return ans;
}



### 伙伴算法

由于进程申请内存的大小是任意的，如果操作系统对malloc 函数的实现方法不对，将直接导致一个不可避免的问题，那就是**内存碎片。这些块虽然是空闲的，但是却小到无法使用**。随着申请和释放次数的增加，内存将变得越来越不连续。最后，整个内存将只剩下碎片，即使有足够的空闲页框可以满足请求，但要分配一个大块的连续页框就可能无法满足，所以减少内存浪费的核心就是尽量避免产生内存碎片。针对这样的问题，有很多行之有效的解决方法，其中**伙伴算法被证明是非常行之有效的一套内存管理方法**，因此也被相当多的操作系统所采用。

伙伴算法（Buddy system）**把所有的空闲页框分为11个块链表**，每块链表中分布包含特定的连续页框地址空间，比如第0个块链表包含大小为2^0个连续的页框，第1个块链表中，每个链表元素包含2^1个页框大小的连续地址空间，….，第10个块链表中，每个链表元素包含2^10个页框大小的连续地址空间；**每个链表元素代表4M的连续地址空间**。每个链表中元素的个数在系统初始化时决定，在执行过程中，动态变化。

   伙伴算法每次只能分配2的幂次页的空间，比如一次分配1页，2页，4页，8页，…，1024页(2^10)等等，**每页大小一般为4K，因此，伙伴算法最多一次能够分配4M的内存空间**。

**内存的分配过程：**

1. 如果需要分配4K，即一个页框大小的内存，**首先去链表0查看是否有空闲块**；
2. 如果有空闲块，分配成功；**如果没有链表块，查看下一级，即链表1是否有空闲块**；
3. 如果链表1有空闲块，则**将这块内存分成2块**，一块返回，一块给到链表0；如果没有则以此类推；
4. 如果请求分配的不是2次幂的大小，则会分配比该数要大一点的2次幂的块，**因此会产生内部碎片；**

**回收过程：**

1. 首先定义什么是伙伴，满足三个条件：**①两个块具有相同大小；②物理地址是连续的；③从同一个大块中拆分出来；**
2. 当我们回收到一个大小为b的块的时候，首先检查b的链表里面有没有空闲块，**如果有空闲块并且地址连续，**就将其合并成一个2b的块，然后以此内推，直到不能合或者得到一个2^10的最大块为止；









### linux中SSH是什么？

ssh服务是一个**守护进程，由系统后台监听客户端的连接**，进程名为sshd，端口为22。通过SSH客户端我们可以连接到运行了SSH服务器的远程机器上，也就是说，我们可以**通过ssh来远程控制我们的电脑或者服务器**。那么ssh协议的优点就是**数据传输是加密**的，可以防止信息泄露，而且数据传输是压缩的，可以提高传输速度。

1. 在命令行中输入“**ssh -l root 服务器IP**”可以连接到服务器，也可以使用“**ssh root@服务器IP**”连接到服务器。例如我们使用deepin1：

   ```bush
   ssh -p 22 deepin2@192.168.56.132
   ```

   这里的-p 22 表示22端口，可以忽略；deepin2是我们想连接的那个服务器的用户名，@后面的是deepin2的IP地址；后续还需要输入deepin2的密码；然后就可以直接运行cmd命令行来操作我们的服务器了；

2. **免密登陆：**

   1. 首先，配置公钥。在deepin1终端使用**ssh-keygen**生成公钥；
   2. 然后，上传公钥到服务器。在Deepin1终端中执行ssh-copy-id -p port user@remotr（ssh-copy-id -p 22 deepin2@192.168.56.132）可以让远程服务器记住我们；
   3. 现在连接deepin2不需要密码了；



### accept发生在三次握手哪个阶段？

答案是发生在**三次握手完成之后**。

服务器：申请socket==>setsockopt（可选）==>bind==>listen==>等待连接==>accept==>read==>write==>主动或者被动close；

客户端：申请socket==>setsockopt（可选）==>connect==>write==>read==>主动或者被动close；



### linux基础知识

&  表示任务在后台执行，如要在后台运行redis-server,则有 redis-server &

&& 表示前一条命令执行成功时，才执行后一条命令 ，如 echo '1‘ && echo '2'   

| 表示管道，上一条命令的输出，作为下一条命令参数，如 echo 'yes' | wc -l

|| 表示上一条命令执行失败后，才执行下一条命令，如 cat nofile || echo "fail"



### 如何实现一个单例模式？

单例模式，是一种常用的软件设计模式。在它的核心结构中只包含一个被称为单例的特殊类。通过单例模式可以保证系统中，**应用该模式的类一个类只有一个实例**。

单例模式分类：

- 饿汉式单例模式：在类加载时就完成了初始化，所以类加载比较慢、获取对象的速度快、以空间换取时间模式、**线程安全**；
- 懒汉式单例模式：在类加载时不初始化、按照需求创建实例、以时间换取空间模式；

具体方法是**将该类的构造函数声明为private**，同时复制构造函数和赋值运算符也声明为private，防止复制和赋值；如果要生成一个类对象必须通过我们的对外接口getinstance，然后声明一个static的类对象，根据需求可以选择饿汉式或者懒汉式的方法；

问题1：内存如何回收？

我们可以在private内声明一个struct，其析构函数判断instance如果不为空则delete，然后将其声明为静态成员变量，**利用程序结束时会自动释放静态变量的特点**实现对单例的析构；

问题2：线程安全吗？

不安全，所以需要用到一个互斥锁，但是简单地使用锁会导致多个线程阻塞在锁的获取，所以可以在加锁前判断instance==NULL，即double check。

代码（懒汉式）：

```cpp
class Singleton
{
  private:
    static Singleton *local_instance;
    static pthread_mutex_t mutex;
    Singleton(){
        cout << "构造" << endl;
    };
    ~Singleton(){
        cout << "析构" << endl;
    }
    class rememberFree{
        public:
        rememberFree(){
            cout << "成员构造" << endl;
        }
        ~rememberFree(){
            if(Singleton::local_instance != nullptr){
                delete Singleton::local_instance;
            }
        }
    };
    static rememberFree remember;

  public:
    static Singleton *getInstance()
    {
        if (local_instance == nullptr){
        	pthread_mutex_lock(&mutex);
        	if (local_instance == nullptr)
        	{
            	local_instance = new Singleton();
        	}
        	pthread_mutex_unlock(&mutex);
        }
        return local_instance;
    }
};

Singleton * Singleton::local_instance = nullptr;
pthread_mutex_t Singleton::mutex = PTHREAD_MUTEX_INITIALIZER;
Singleton::rememberFree Singleton::remember;
int main()
{
    cout << "单例模式访问第一次前" << endl;
    Singleton * s = Singleton::getInstance();
    cout << "单例模式访问第一次后" << endl;
    cout << "单例模式访问第二次前" << endl;
    Singleton * s2 = Singleton::getInstance();
    cout << "单例模式访问第二次后" << endl;
    return 0;
}
```



### 如何实现一个工厂模式？

工厂模式一般分为三种：**简单工厂模式、工厂方法模式、抽象工厂模式**。

1. 简单工厂模式：

   简单工厂模式，工厂类是创建产品的，它决定创建哪一种产品，就像领导决定采用那种技术方案样。举个例子，现在有宝马车和奔驰车两种车需要生产，但是只有一个工厂，且只能在同一时间生产一种车，这时就有工厂决定生产那种车了。**简单来说，就是根据给定的类型返回对应的类对象就ok了。**但是存在一个问题：每次增加车型的时候都需要修改工厂类，违反了开放封闭原则，即软件实体（类、模块、函数）可以扩展，但是不可修改。

   **优点**：工厂类中包含了必要的逻辑判断，可以根据用户的需求动态实例化相关的类；对客户端来说，去除了与具体产品的依赖。

   **缺点**：违背开放-封闭原则，添加新的产品时需要修改工厂类的内容。

   ![](img/jdgc.jpg)

   简单描述：我们以运算类为基类，派生了很多类，客户端通过工厂或者这些派生类，**要是要增加新的派生类需要修改工厂类，违反开放-封闭原则；**

   代码：

   ```bash
   #include <iostream>
   using namespace std;
   
   enum CarType{BENZ, BMW};
   
   class Car//车类
   {
   public:
       virtual void createdCar(void) = 0;
   };
   
   class BenzCar : public Car //奔驰车
   {
   public:
       BenzCar()
       {
           cout<<"Benz::Benz()"<<endl;
       }
       virtual void createdCar(void)
       {
           cout<<"BenzCar::createdCar()"<<endl;
       }
       ~BenzCar()
       {
   
       }
   };
   
   class BmwCar : public Car //宝马车
   {
   public:
       BmwCar()
       {
           cout<<"Bmw::Bmw()"<<endl;
       }
       virtual void createdCar(void)
       {
           cout<<"BmwCar::createdCar()"<<endl;
       }
   };
   
   
   class CarFactory //车厂
   {
   public:
       Car* createSpecificCar(CarType type)
       {
           switch(type)
           {
           case BENZ://生产奔驰车
               return (new BenzCar());
               break;
           case BMW://生辰宝马车
               return (new BmwCar());
               break;
           default:
               return NULL;
               break;
           }
       }
   };
   
   int main(int argc, char** argv)
   {
       CarFactory carfac;
       Car* specificCarA = carfac.createSpecificCar(BENZ);//看到网上众多示例在new后没有delete，感觉不是特别严谨
       Car* specificCarB = carfac.createSpecificCar(BMW);
   
       delete specificCarA; delete specificCarB;
       
       return 0;
   }
   ```

2. 工厂方法模式

   针对简单工厂违反开放封闭原则出现的设计模式。不再只由一个工厂类决定那一个产品类应当被实例化,这个决定权被交给子类去做。当有新的产品（新型汽车）产生时，只要按照抽象产品角色、抽象工厂角色提供的方法来生成即可（新车型可以用一个新类继承创建产品即可），那么就可以被客户使用，而不必去修改任何已有的代码。**简单来说，就是不再依赖于工厂去返回我们需要的对象，而是将工厂作为基类，根据我们的需求去派生出对应的工厂类，利用这个工厂类产生我们需要的对象。**

   **优点**：克服了简单工厂违背开放-封闭原则的缺点。

   **缺点**：每增加一个产品，需要多增加一个对应工厂的类，增加了额外的开发量。

   ![](img/gc.jpg)

   简单描述：以运算类为基类生成了很多派生类，对应地，我们用工厂类为基类派生了很多工厂类，**通过这些派生的工厂类来获取对应的运算类；**这样我们要新增一个运算类就对应新增一个工厂类就行，不修改原来的工厂类；

   代码：

   ```bash
   #include <iostream>
   using namespace std;
   
   class Car//车类
   {
   public:
       virtual void createdCar(void) = 0;
   };
   
   class BenzCar : public Car //奔驰车
   {
   public:
       BenzCar()
       {
           cout<<"Benz::Benz()"<<endl;
       }
       virtual void createdCar(void)
       {
           cout<<"BenzCar::createdCar()"<<endl;
       }
       ~BenzCar()
       {
   
       }
   };
   
   class BmwCar : public Car //宝马车
   {
   public:
       BmwCar()
       {
           cout<<"Bmw::Bmw()"<<endl;
       }
       virtual void createdCar(void)
       {
           cout<<"BmwCar::createdCar()"<<endl;
       }
   };
   
   
   class Factory//车厂
   {
   public:
       virtual Car* createSpecificCar(void) = 0;
   };
   
   class BenzFactory : public Factory//奔驰车厂
   {
   public:
       virtual Car* createSpecificCar(void)
       {
           return (new BenzCar());
       }
   };
   
   class BmwFactory : public Factory//宝马车厂
   {
   public:
       virtual Car* createSpecificCar(void)
       {
           return (new BmwCar());
       }
   };
   
   
   int main(int argc, char** argv)
   {
       Factory* factory = new BenzFactory();
       Car* specificCarA = factory->createSpecificCar();
       factory = new BmwFactory();
       Car* specificCarB = factory->createSpecificCar();
       
       delete factory; delete specificCarA; delete specificCarB;
       
       return 0;
   }
   ```

3. 抽象工厂模式

   如果一个工厂需要生产某产品的高端定制版，但是又不想重新定义一个工厂类，就出现了抽象工厂模式。

   **优点**：需求改变时改动最小；具体的创建实例过程与客户端分离，客户端通过抽象接口操作实例，产品的具体类名也被具体工厂的实现分离，不出现在客户端代码中（客户端只知道有一个抽象工厂，一个抽象的Engine和一个抽象的Type）。

   **缺点**；新增功能时，比如火车和飞机都有窗户，那就要增加3个类，还要修改2个具体的工厂类。

   ![](img/cxgc.jpg)

   简单描述：有多种不同类型的纯虚基类，派生出各式各样的派生类；我们的工厂也是一个纯虚基类，**但是这个基类中有多种产品的构造方法**，我们通过派生这个工厂来获取可以生成多种产品的派生类；
   
   代码：
   
   ```bash
   #include <iostream>
   using namespace std;
   
   class Car//车类
   {
   public:
       virtual void createdCar(void) = 0;
   };
   
   class BenzCar : public Car //奔驰车
   {
   public:
       BenzCar()
       {
           cout<<"Benz::Benz()"<<endl;
       }
       virtual void createdCar(void)
       {
           cout<<"BenzCar::createdCar()"<<endl;
       }
       ~BenzCar()
       {
   
       }
   };
   
   class BmwCar : public Car //宝马车
   {
   public:
       BmwCar()
       {
           cout<<"Bmw::Bmw()"<<endl;
       }
       virtual void createdCar(void)
       {
           cout<<"BmwCar::createdCar()"<<endl;
       }
   };
   
   class HighCar //高配版车型
   {
   public:
       virtual void createdCar(void) = 0;
   };
   
   class HighBenzCar : public HighCar //高配奔驰车
   {
   public:
       HighBenzCar()
       {
           cout<<"HighBenzCarBenz::Benz()"<<endl;
       }
       virtual void createdCar(void)
       {
           cout<<"HighBenzCar::createdCar()"<<endl;
       }
   };
   
   class HighBmwCar : public HighCar //高配宝马车
   {
   public:
       HighBmwCar()
       {
           cout<<"HighBmwCar::Bmw()"<<endl;
       }
       virtual void createdCar(void)
       {
           cout<<"HighBmwCar::createdCar()"<<endl;
       }
   };
   
   class Factory//车厂
   {
   public:
       virtual Car* createSpecificCar(void) = 0;
       virtual HighCar* createdSpecificHighCar(void) = 0;
   };
   
   class BenzFactory : public Factory//奔驰车厂
   {
   public:
       virtual Car* createSpecificCar(void)
       {
           return (new BenzCar());
       }
   
       virtual HighCar* createdSpecificHighCar(void)
       {
           return (new HighBenzCar());
       }
   };
   
   class BmwFactory : public Factory//宝马车厂
   {
   public:
       virtual Car* createSpecificCar(void)
       {
           return (new BmwCar());
       }
       virtual HighCar* createdSpecificHighCar(void)
       {
           return (new HighBmwCar());
       }
   };
   
   
   int main(int argc, char** argv)
   {
       Factory* factory = new BenzFactory();
       Car* specificCar = factory->createSpecificCar();
       HighCar* spcificHighCar = factory->createdSpecificHighCar();
       
       delete factory; delete specificCar; delete spcificHighCar;
       
       return 0;
   }
   ```







### 为什么有了二叉查找树、二叉平衡树还需要红黑树呢？不同应用场景如何选择红黑树和哈希表？

1. 二叉查找树：

   优点：有序；

   缺点：如果插入顺序不当，会退化成链表；

2. 平衡二叉树：

   优点：有序，且任意左右子树高度差不大于1；

   缺点：插入和删除的后处理太过复杂，在数据量极大的情况下需要花费大量时间重新平衡；

3. 红黑树：

   一种弱化版的平衡二叉树，不要求任意左右子树高度差不大于1，所以插入和删除的后处理相对简单点。

4. 那为什么不用hash要用红黑树呢？

   1. 查找速度：hash的查找速度是O(1),红黑树是O（logn）；
   2. 内存消耗：hash需要一大块内存来映射，所以会有未使用的内存；红黑树取得的内存就是已使用的内存；
   3. 插入和删除：hash是O（1），红黑树是O（logn）；
   4. 数据有序性：hash的数据是无序的，红黑树存储的数据是有序的；



### 什么是跳表？为什么Redis不用红黑树用跳表？

跳表是一种带索引的链表，结合了数组查找的优点和链表插入删除的优点，查询、插入删除复杂度均为O（logn），也因此需要额外的空间存储索引。**还支持范围查找。**

![](img/sl.png)

如上图所示，最下面的才是存储N个数据的链表，第一级索引一般有N/2个节点，第二级一般有N/4个节点，因此第k层索引有N/（2^K）个节点。

1. 查找

   查找从最高级索引开始，当前节点小于查询值，说明在当前节点的后面，此时如果当前节点的next不为空，则继续查询；否则就转移到当前节点的down，即下一级索引继续查找；直到到达最后链表；**加入有h级索引，那么h级索引的节点数为N/（2^h）个，第h级有两个节点，不然没有意义；此时的索引的深度为h=logN-1，因此查找的最多查找logN次就能到达底层，每一层查找次数为常数，所以查找的时间复杂度为O（logn）。**

2. 插入

   首先从最高级节点查询插入的位置，由于插入数据之后也要在索引上添加新的节点，但是如果每次插入都严格按照定义去维护索引复杂度为特别高，所以**采用随机技术决定要在多少层索引添加节点**；例如，通过查询在原始链表找到插入的位置了，然后有0.5的概率插入到一级索引；然后又有0.5的概率插入到二级索引，也就是0.25的概率会插入到二级索引，因为一级没有的节点二级也不会有；因此用概率来保证i级索引只有（0.5）^i个节点。

3. 删除

   删除的同时必须将对应的索引节点也删除了，**从最高级索引开始查找，同时标记命中的节点，**然后开始全部删除；



### 字节跳动面试手撕代码

给定一个多边形各个点的坐标pi，每条边都是垂直或者水平的。给定一个k，将其周长分割成k段，返回每一段的端点坐标。

![](img/zjms.png)

首先使用struct存储坐标（x，y），还有一个哈希表存储对应的变长，**注意这里不要漏了最后一段边长**；我的做法里面对应的lenwh[i]表示rectangle[i]和rectangle[i+1]之间的长度；

1. 首先用totallen统计出周长，然后计算平均每段的长度avglen，这个必须是double，因为不一定能整除；
2. 首先wh[0]这个点肯定是其中一个点，先入队；
3. 初始化judge=avglen，用judge判断是否应该到达下一段；如果judeg小于等于当前的line，说明这一条边上面有一个点，**注意这个点不知道是从坐标点向左还是向右，向上还是向下得到，所以要判断清楚**；获取完这一个点之后，将judeg+=avglen，这是到达下一个点的长度；
4. 如果judge大于当前的line，说明这一条边没用了，用当前的judge减去这一条边的长度，同时lineindex++，下一个循环会自动检查下一条边；

代码：

```c++
#include<bits/stdc++.h>
#include<map>
#include<unordered_map>
#include<thread>
#include<mutex>
#include<Windows.h>
//#include"Bank.h"
using namespace std;
/*
输入：
6 8
0 0
4 0
4 4
3 4
3 1
0 1
输出：
0，0
2，0
4，0
4，2
4，4
3，3
3，1
1，1
*/
struct Node {//这个点需要用double
	double x, y;
	Node(double x_ = 0, double y_ = 0) {
		x = x_;
		y = y_;
	}
};
int main() {
	int ordnum, divide, totallen = 0;
	cin >> ordnum >> divide;
	vector<Node> wh(ordnum), ans;
	unordered_map<int, int> line;
	for (int i = 0; i < ordnum; ++i) {
		cin >> wh[i].x >> wh[i].y;
		if (i){
			totallen += abs(wh[i].x - wh[i - 1].x) + abs(wh[i].y - wh[i - 1].y);
			line[i - 1] = abs(wh[i].x - wh[i - 1].x) + abs(wh[i].y - wh[i - 1].y);
		}
		if (i == ordnum - 1) {
			totallen += abs(wh[i].x - wh[0].x) + abs(wh[i].y - wh[0].y);
			line[i] = abs(wh[i].x - wh[0].x) + abs(wh[i].y - wh[0].y);
		}
	}
	ans.push_back(Node(wh[0].x, wh[0].y));//第一个点肯定是结果
	double avglen = totallen * 1.0 / divide, judge=avglen;
	int pointcount = 0, lineindex = 0;
	while (pointcount < divide - 1) {
		if (judge <= line[lineindex]) {//如果当前judge小于line，这一边肯定有一个点
			Node temp;
			if (wh[lineindex + 1].x == wh[lineindex].x) {
				temp.x = wh[lineindex].x;
				temp.y = wh[lineindex + 1].y > wh[lineindex].y ? wh[lineindex].y + judge : wh[lineindex].y - judge;
			}
			else {
				temp.y = wh[lineindex].y;
				temp.x = wh[lineindex + 1].x > wh[lineindex].x ? wh[lineindex].x + judge : wh[lineindex].x - judge;
			}
            ans.push_back(temp);
			judge += avglen;//每次加上avglen，下一次会判断下一个点是否还在这条边上
			pointcount++;
		}
		else//如果judge大于line，说明这条边没有了，减去这一条边的长度，检查下一条边
			judge -= line[lineindex++];
	}
	for (int i = 0; i < divide; ++i)
		cout << ans[i].x << "," << ans[i].y << endl;
    return 0;
}
```





### 你的WebServer里面主要的CPU占用和内存占用都用到哪里去了？

1. 由于压测客户端与服务器之间使用长连接，客户端接收http响应报文之后没有进行断开。**维持大量的长连接占用大量的系统内存，监听和connect是几乎不占内存的，占用内存的是滑动窗口的读写缓存；**
2. 维持大量的短连接，导致accept比较频繁，cpu占用率会大幅上升；或者epoll使用水平触发导致系统频繁进行轮询也会占用大量的cpu；
3. 系统中存在大量time_wait，导致多个端口被占用，最后无法建立tcp连接；







### 一条SQL执行很慢有什么原因？

1. 如果只是**偶尔查询很慢**

   1. 当我们要往数据库插入一条数据、或者要更新一条数据的时候，我们知道数据库会在**内存**中把对应字段的数据更新了，但是更新之后，这些更新的字段并不会马上同步持久化到**磁盘**中去，而是把这些更新的记录写入到 redo log （innoDB特有，mySQL只有binlog，binlog没有空间的限制）日记中去，等到空闲的时候，在通过 redo log 里的日记把最新的数据同步到**磁盘**中去。不过，**redo log 里的容量是有限的**，如果数据库一直很忙，更新又很频繁，这个时候 redo log 很快就会被写满了，这个时候就没办法等到空闲的时候再把数据同步到磁盘的，只能暂停其他操作，全身心来把数据同步到磁盘中去的，而这个时候，**就会导致我们平时正常的SQL语句突然执行的很慢**，所以说，数据库在在同步数据到磁盘的时候，就有可能导致我们的SQL语句执行的很慢了。
   2. 第二种情况是查询涉及的表或者行被加锁了，所以需要等待锁释放了才可以查询；

2. **查询一直很慢**

   1. **没有用上索引**。例如你的表中有字段a、b、c，但是只有a有索引，这个时候你以b或者c作为约束查询，那只能进行全表过滤，表很大的时候速度就会特别慢；

   2. **还是没有用上索引。**例如你的c字段有索引，但是你查询的约束为c - 1 = 1000，则不会使用索引，只有查询c = 1001才会用上c字段的索引；此外，当左侧使用了函数的时候，也会导致没有用上索引；（存疑，难道不会自动优化？）

   3. **数据库选错索引。主键索引和非主键索引是有区别的**，主键索引存放的值是**整行字段的数据**，而非主键索引上存放的值不是整行字段的数据，而且存放**主键字段的值**。在我们进行查询的时候，**系统会进行判断，是使用全表扫描一次完成；还是使用非主键索引扫描，两次完成；**系统的选择主要是根据**索引的区分度**，当一个索引上面不同的值越多，其区分度就越大；因此，区分度越大的索引，查询的效率就越高；但是每次都检查索引的区分度代价太大，**因此系统会通过采样来判断此索引的区分度**，如果采样预测的区分度很小，就会进行全表扫描，这样就很慢了；

      解决方法：

      ①select \* from T force index（primary） where c<100这一句强制使用a所谓索引来进行查询。

      ②先使用show index from T；查看索引的区分度；如果区分度不准确就使用analyze table T；



### 主键索引和非主键索引的区别？

1. 主键索引的**data域存放了对应一行的数据**，并且是有序的，所以是**聚簇索引**；
2. 非主键索引其**data域存放的是主键的值，所以当表被修改的时候，不需要进行大幅度的修改，甚至可以不修改；**但也因此需要再次索引才能得到整行数据，因此也称为二级索引，这个过程称为回表；
3. 主键索引不能为NULL，非主键索引可以为NULL；
4. 主键索引只能有一个，非主键索引可以有多个；



### 为什么主键索引最好使用自增？

由于对于B+树来说，如果每次插入的加点key都比之前要大，那就可以很方便地直接在最后面插入这个新的节点；如果新插入的节点key处于中间，那就可能需要重新调整B+树的结果，最坏的结果是存储该数据的那个页已经满了，需要进行页分裂才能完成调整。





### 打开一个url全过程？

1. 一般我们使用浏览器去浏览这个url，**首先，需要将域名解析为IP地址。**首先从浏览器缓存和操作系统hosts文件中查找是否存在所需的ip地址，如果没有，就需要通过DUP协议向本地域名服务器查询对应的IP地址，如果还是没有就需要向更高级的域名服务器查询；
2. 生成一个请求报文，然后在浏览器的缓存里面匹配，如果命中了，就直接从缓存取得响应报文；
3. 获得了对方的IP地址之后，就可以根据TCP协议通过三次握手与服务器建立TCP连接；
4. 如果我们使用的是HTTPS，还需要与服务器进行加密算法、压缩算法的协商，并交换密钥；
5. 然后将浏览器生成的HTTP请求报文分割成多个报文段，进行传输；
6. 在传输的过程中，TCP协议会使用流量控制和拥塞避免的相关算法，保证我们的报文段能够完整按序到达；
7. 在物理层进行传输都是基于MAC地址的，这就需要ARP地址解析协议获取服务器的物理地址；在各个路由器之间跳转也需要对应的路由算法进行路由选择，例如OSPF开放最短路径优先路由算法搜索到达服务器的路径，通过PPP点对点协议在数据链路层上封装成帧，最后通过物理层传输到服务器；
8. 现在提供服务的一般都是一个代理服务器，通过代理服务器可以实现负载均衡、容错容灾等功能；我们的http请求最终会被代理服务器分配到一个真正的服务端为我们提供服务；
9. 服务器解析HTTP请求报文，如果能够通过安全验证、权限验证，服务器就会执行响应的服务，例如查询数据库、获取对应的页面等，然后生成对应的HTTP响应报文，返回给代理服务器，由它返回给客户端；
10. 浏览器收到的HTTP响应报文后首先在缓存里留存一份，然后渲染页面和数据，然后就能显示页面；
11. 如果是短连接，就通过四次挥手断开连接，如果是长连接，则保持连接；



### mySQL中int（4）和int（8）的区别？char（4）和varchar（4）的区别？

1. int（4）和int（8）：

   正常使用的话，他们并没有什么区别，**int(M)，这个M表示的是显示宽度**，只有在**加上关键字zerofill**的时候，才会有点儿效果比如int(4)，当插入的数据不够4位时，会在数据前面用0补满4位，当超过4位时；

   create table ‘test’（age int（2） **unsigned zerofill** not null default ‘00’）

   当输入的年龄小于2位的时候，前面会补一个0，**当输入的数字超过2位，不会缩小为2位，照常显示；**其实其实际存储都是4字节的一个int整型；

2. char（4）和varchar（4）：

   1. **char的长度是不可变的，而varchar的长度是可变的；**
   2. 定义一个**char[10]如果存进去的是‘abcd’,那么char所占的长度依然为10，除了字符‘abcd’外，后面跟六个空格**；而varchar[10]就立马把长度变为4了，取数据的时候，char类型的要用trim()去掉多余的空格，而varchar是不需要的；
   3. **char的存取速度还是要比varchar要快得多**，因为其长度固定，方便程序的存储与查找；但是char也为此付出的是空间的代价，因为其长度固定，所以难免会有多余的空格占位符占据空间，可谓是以空间换取时间效率，而varchar是以空间效率为首位的。
   4. char的存储方式是，对英文字符（ASCII）占用1个字节，对一个汉字占用两个字节；而varchar的存储方式是，对每个英文字符占用2个字节，汉字也占用2个字节，两者的存储数据都非unicode的字符数据。
   5. 对于varchar，**当数据长度小于255时，数据库采用1个字节记录varchar数据长度**，当数据长度>255时，需要用两个字节存储长度；
   6. char类型字段的最大长度是255，且255个字节可全部用于存储数据；vachar字段的类型最大长度是65535，但实际存储的数据长度要小于该值；



### mySQL中空值和NULL值有什么区别？

1. 空值不占空间，NULL值占空间；
2. 定义为NOT NULL的字段只能插入空值，不能插入null值；而NULL字段可以插入空值，也可以插入null值。
3. 可以发现 is not null 只会过滤为null值的列，而=会同时过滤空值和null值，所以要根据实际情况选择过滤方式。因此，**判断null值只能用 is null 或 is not null ，不能用 = 或 <>。**
4. 在进行count()统计某列的记录数的时候，如果采用的NULL值，会别系统自动忽略掉，但是**空值是会进行统计到其中的。 **
5. 当使用ORDER BY时，首先呈现NULL值。如果你用DESC以降序排序，NULL值最后显示。即**排序时默认NULL值比空值小**；
6. 当使用GROUP BY时，所有的NULL值被认为是相等的，故只显示一行。



### 进程、线程、协程、管程？

1、进程

进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动,进程是**系统进行资源分配和调度的一个独立单位。每个进程都有自己的独立内存空间，不同进程通过进程间通信来通信**。由于进程比较重量，占据独立的内存，所以上下文进程间的切换开销（栈、寄存器、虚拟内存、文件句柄等）比较大，但相对比较稳定安全。

2、线程

线程是进程的一个实体,是**CPU调度的基本单位**,它是比进程更小的能独立运行的基本单位.**线程自己基本上不拥有系统资源,只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈)**,但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源。**线程间通信主要通过共享内存**，上下文切换很快，资源开销较少，但相比进程不够稳定容易丢失数据。

3、协程

**协程是一种用户态的轻量级线程，**协程的调度完全由用户控制。**协程拥有自己的寄存器上下文和栈**。协程调度切换时，将寄存器上下文和栈保存到其他地方，在切回来的时候，恢复先前保存的寄存器上下文和栈，直接操作栈则基本没有内核切换的开销，可以不加锁的访问全局变量，所以上下文的切换非常快。

4、管程

管程在功能上和信号量及PV操作类似，属于一种进程同步互斥工具，但是具有与信号量及PV操作不同的属性。使用管程可以将**分散在各进程中的临界区集中起来进行管理；防止进程有意或无意的违法同步操作；**所有进程都可以访问管程，但是**同一时刻只能有一个进程**访问管程；

**四者的区别：**

1. 多个进程间地址空间相互独立，如果其中一个进程崩溃了，其他进程不受影响；多个线程共享同一个进程的地址空间，如果其中一个线程崩溃了，整个进程就崩溃了；
2. 进程是资源配置的基本单位，线程是处理机调度的基本单位；
3. 协程可以通过yield来调用其它协程。通过yield方式转移执行权的协程之间**不是调用者与被调用者**的关系，而是彼此对称、平等的。**协程的生命期完全由他们的使用的需要决定。**
4. 线程和进程的切换都是内核态的，而协程的切换是用户态的，开销最小；



### HTTP状态码解析

| 状态码  | 含义                                                         |
| :------ | :----------------------------------------------------------- |
| 100     | 客户端应当继续发送请求。这个临时响应是用来通知客户端它的部分请求已经被服务器接收，且仍未被拒绝。客户端应当继续发送请求的剩余部分，或者如果请求已经完成，忽略这个响应。服务器必须在请求完成后向客户端发送一个最终响应。 |
| 101     | 服务器已经理解了客户端的请求，并将通过Upgrade 消息头通知客户端采用不同的协议来完成这个请求。在发送完这个响应最后的空行后，服务器将会切换到在Upgrade 消息头中定义的那些协议。 　　只有在切换新的协议更有好处的时候才应该采取类似措施。例如，切换到新的HTTP 版本比旧版本更有优势，或者切换到一个实时且同步的协议以传送利用此类特性的资源。 |
| 102     | 由WebDAV（RFC 2518）扩展的状态码，代表处理将被继续执行。     |
| **200** | **请求已成功，请求所希望的响应头或数据体将随此响应返回。**   |
| 201     | 请求已经被实现，而且有一个新的资源已经依据请求的需要而建立，且其 URI 已经随Location 头信息返回。假如需要的资源无法及时建立的话，应当返回 '202 Accepted'。 |
| **202** | **服务器已接受请求，但尚未处理。**正如它可能被拒绝一样，最终该请求可能会也可能不会被执行。在异步操作的场合下，没有比发送这个状态码更方便的做法了。 返回202状态码的响应的目的是允许服务器接受其他过程的请求（例如某个每天只执行一次的基于批处理的操作），而不必让客户端一直保持与服务器的连接直到批处理操作全部完成。在接受请求处理并返回202状态码的响应应当在返回的实体中包含一些指示处理当前状态的信息，以及指向处理状态监视器或状态预测的指针，以便用户能够估计操作是否已经完成。 |
| 203     | 服务器已成功处理了请求，但返回的实体头部元信息不是在原始服务器上有效的确定集合，而是来自本地或者第三方的拷贝。当前的信息可能是原始版本的子集或者超集。例如，包含资源的元数据可能导致原始服务器知道元信息的超级。使用此状态码不是必须的，而且只有在响应不使用此状态码便会返回200 OK的情况下才是合适的。 |
| 204     | 服务器成功处理了请求，但不需要返回任何实体内容，并且希望返回更新了的元信息。响应可能通过实体头部的形式，返回新的或更新后的元信息。如果存在这些头部信息，则应当与所请求的变量相呼应。 　　如果客户端是浏览器的话，那么用户浏览器应保留发送了该请求的页面，而不产生任何文档视图上的变化，即使按照规范新的或更新后的元信息应当被应用到用户浏览器活动视图中的文档。 　　由于204响应被禁止包含任何消息体，因此它始终以消息头后的第一个空行结尾。 |
| 205     | 服务器成功处理了请求，且没有返回任何内容。但是与204响应不同，返回此状态码的响应要求请求者重置文档视图。该响应主要是被用于接受用户输入后，立即重置表单，以便用户能够轻松地开始另一次输入。 　　与204响应一样，该响应也被禁止包含任何消息体，且以消息头后的第一个空行结束。 |
| 206     | 服务器已经成功处理了部分 GET 请求。类似于 FlashGet 或者迅雷这类的 HTTP 下载工具都是使用此类响应实现断点续传或者将一个大文档分解为多个下载段同时下载。 　　该请求必须包含 Range 头信息来指示客户端希望得到的内容范围，并且可能包含 If-Range 来作为请求条件。 　　响应必须包含如下的头部域： 　　Content-Range 用以指示本次响应中返回的内容的范围；如果是 Content-Type 为 multipart/byteranges 的多段下载，则每一 multipart 段中都应包含 Content-Range 域用以指示本段的内容范围。假如响应中包含 Content-Length，那么它的数值必须匹配它返回的内容范围的真实字节数。 　　Date 　　ETag 和/或 Content-Location，假如同样的请求本应该返回200响应。 　　Expires, Cache-Control，和/或 Vary，假如其值可能与之前相同变量的其他响应对应的值不同的话。 　　假如本响应请求使用了 If-Range 强缓存验证，那么本次响应不应该包含其他实体头；假如本响应的请求使用了 If-Range 弱缓存验证，那么本次响应禁止包含其他实体头；这避免了缓存的实体内容和更新了的实体头信息之间的不一致。否则，本响应就应当包含所有本应该返回200响应中应当返回的所有实体头部域。 　　假如 ETag 或 Last-Modified 头部不能精确匹配的话，则客户端缓存应禁止将206响应返回的内容与之前任何缓存过的内容组合在一起。 　　任何不支持 Range 以及 Content-Range 头的缓存都禁止缓存206响应返回的内容。 |
| 207     | 由WebDAV(RFC 2518)扩展的状态码，代表之后的消息体将是一个XML消息，并且可能依照之前子请求数量的不同，包含一系列独立的响应代码。 |
| 300     | 被请求的资源有一系列可供选择的回馈信息，每个都有自己特定的地址和浏览器驱动的商议信息。用户或浏览器能够自行选择一个首选的地址进行重定向。 　　除非这是一个 HEAD 请求，否则该响应应当包括一个资源特性及地址的列表的实体，以便用户或浏览器从中选择最合适的重定向地址。这个实体的格式由 Content-Type 定义的格式所决定。浏览器可能根据响应的格式以及浏览器自身能力，自动作出最合适的选择。当然，RFC 2616规范并没有规定这样的自动选择该如何进行。 　　如果服务器本身已经有了首选的回馈选择，那么在 Location 中应当指明这个回馈的 URI；浏览器可能会将这个 Location 值作为自动重定向的地址。此外，除非额外指定，否则这个响应也是可缓存的。 |
| **301** | **被请求的资源已永久移动到新位置，并且将来任何对此资源的引用都应该使用本响应返回的若干个 URI 之一。**如果可能，拥有链接编辑功能的客户端应当自动把请求的地址修改为从服务器反馈回来的地址。除非额外指定，否则这个响应也是可缓存的。 　　新的永久性的 URI 应当在响应的 Location 域中返回。除非这是一个 HEAD 请求，否则响应的实体中应当包含指向新的 URI 的超链接及简短说明。 　　如果这不是一个 GET 或者 HEAD 请求，因此浏览器禁止自动进行重定向，除非得到用户的确认，因为请求的条件可能因此发生变化。 　　注意：对于某些使用 HTTP/1.0 协议的浏览器，当它们发送的 POST 请求得到了一个301响应的话，接下来的重定向请求将会变成 GET 方式。 |
| **302** | **请求的资源现在临时从不同的 URI 响应请求。由于这样的重定向是临时的，客户端应当继续向原有地址发送以后的请求。**只有在Cache-Control或Expires中进行了指定的情况下，这个响应才是可缓存的。 　　新的临时性的 URI 应当在响应的 Location 域中返回。除非这是一个 HEAD 请求，否则响应的实体中应当包含指向新的 URI 的超链接及简短说明。 　　如果这不是一个 GET 或者 HEAD 请求，那么浏览器禁止自动进行重定向，除非得到用户的确认，因为请求的条件可能因此发生变化。 　　注意：虽然RFC 1945和RFC 2068规范不允许客户端在重定向时改变请求的方法，但是很多现存的浏览器将302响应视作为303响应，并且使用 GET 方式访问在 Location 中规定的 URI，而无视原先请求的方法。状态码303和307被添加了进来，用以明确服务器期待客户端进行何种反应。 |
| 303     | 对应当前请求的响应可以在另一个 URI 上被找到，而且客户端应当采用 GET 的方式访问那个资源。这个方法的存在主要是为了允许由脚本激活的POST请求输出重定向到一个新的资源。这个新的 URI 不是原始资源的替代引用。同时，303响应禁止被缓存。当然，第二个请求（重定向）可能被缓存。 　　新的 URI 应当在响应的 Location 域中返回。除非这是一个 HEAD 请求，否则响应的实体中应当包含指向新的 URI 的超链接及简短说明。 　　注意：许多 HTTP/1.1 版以前的 浏览器不能正确理解303状态。如果需要考虑与这些浏览器之间的互动，302状态码应该可以胜任，因为大多数的浏览器处理302响应时的方式恰恰就是上述规范要求客户端处理303响应时应当做的。 |
| **304** | **如果客户端发送了一个带条件的 GET 请求且该请求已被允许，而文档的内容（自上次访问以来或者根据请求的条件）并没有改变，则服务器应当返回这个状态码。**304响应禁止包含消息体，因此始终以消息头后的第一个空行结尾。 　　该响应必须包含以下的头信息： 　　Date，除非这个服务器没有时钟。假如没有时钟的服务器也遵守这些规则，那么代理服务器以及客户端可以自行将 Date 字段添加到接收到的响应头中去（正如RFC 2068中规定的一样），缓存机制将会正常工作。 　　ETag 和/或 Content-Location，假如同样的请求本应返回200响应。 　　Expires, Cache-Control，和/或Vary，假如其值可能与之前相同变量的其他响应对应的值不同的话。 　　假如本响应请求使用了强缓存验证，那么本次响应不应该包含其他实体头；否则（例如，某个带条件的 GET 请求使用了弱缓存验证），本次响应禁止包含其他实体头；这避免了缓存了的实体内容和更新了的实体头信息之间的不一致。 　　假如某个304响应指明了当前某个实体没有缓存，那么缓存系统必须忽视这个响应，并且重复发送不包含限制条件的请求。 　　假如接收到一个要求更新某个缓存条目的304响应，那么缓存系统必须更新整个条目以反映所有在响应中被更新的字段的值。 |
| **305** | **被请求的资源必须通过指定的代理才能被访问。**Location 域中将给出指定的代理所在的 URI 信息，接收者需要重复发送一个单独的请求，通过这个代理才能访问相应资源。只有原始服务器才能建立305响应。 　　注意：RFC 2068中没有明确305响应是为了重定向一个单独的请求，而且只能被原始服务器建立。忽视这些限制可能导致严重的安全后果。 |
| 306     | 在最新版的规范中，306状态码已经不再被使用。                  |
| 307     | 请求的资源现在临时从不同的URI 响应请求。由于这样的重定向是临时的，客户端应当继续向原有地址发送以后的请求。只有在Cache-Control或Expires中进行了指定的情况下，这个响应才是可缓存的。 　　新的临时性的URI 应当在响应的 Location 域中返回。除非这是一个HEAD 请求，否则响应的实体中应当包含指向新的URI 的超链接及简短说明。因为部分浏览器不能识别307响应，因此需要添加上述必要信息以便用户能够理解并向新的 URI 发出访问请求。 　　如果这不是一个GET 或者 HEAD 请求，那么浏览器禁止自动进行重定向，除非得到用户的确认，因为请求的条件可能因此发生变化。 |
| **400** | **1、语义有误，当前请求无法被服务器理解。除非进行修改，否则客户端不应该重复提交这个请求。 　　2、请求参数有误。** |
| 401     | 当前请求需要用户验证。该响应必须包含一个适用于被请求资源的 WWW-Authenticate 信息头用以询问用户信息。客户端可以重复提交一个包含恰当的 Authorization 头信息的请求。如果当前请求已经包含了 Authorization 证书，那么401响应代表着服务器验证已经拒绝了那些证书。如果401响应包含了与前一个响应相同的身份验证询问，且浏览器已经至少尝试了一次验证，那么浏览器应当向用户展示响应中包含的实体信息，因为这个实体信息中可能包含了相关诊断信息。参见RFC 2617。 |
| 402     | 该状态码是为了将来可能的需求而预留的。                       |
| **403** | **服务器已经理解请求，但是拒绝执行它。**与401响应不同的是，身份验证并不能提供任何帮助，而且这个请求也不应该被重复提交。如果这不是一个 HEAD 请求，而且服务器希望能够讲清楚为何请求不能被执行，那么就应该在实体内描述拒绝的原因。当然服务器也可以返回一个404响应，假如它不希望让客户端获得任何信息。 |
| **404** | **请求失败，请求所希望得到的资源未被在服务器上发现。**没有信息能够告诉用户这个状况到底是暂时的还是永久的。假如服务器知道情况的话，应当使用410状态码来告知旧资源因为某些内部的配置机制问题，已经永久的不可用，而且没有任何可以跳转的地址。404这个状态码被广泛应用于当服务器不想揭示到底为何请求被拒绝或者没有其他适合的响应可用的情况下。 |
| **405** | **请求行中指定的请求方法不能被用于请求相应的资源。**该响应必须返回一个Allow 头信息用以表示出当前资源能够接受的请求方法的列表。 　　鉴于 PUT，DELETE 方法会对服务器上的资源进行写操作，因而绝大部分的网页服务器都不支持或者在默认配置下不允许上述请求方法，对于此类请求均会返回405错误。 |
| 406     | 请求的资源的内容特性无法满足请求头中的条件，因而无法生成响应实体。 　　除非这是一个 HEAD 请求，否则该响应就应当返回一个包含可以让用户或者浏览器从中选择最合适的实体特性以及地址列表的实体。实体的格式由 Content-Type 头中定义的媒体类型决定。浏览器可以根据格式及自身能力自行作出最佳选择。但是，规范中并没有定义任何作出此类自动选择的标准。 |
| 407     | 与401响应类似，只不过客户端必须在代理服务器上进行身份验证。代理服务器必须返回一个 Proxy-Authenticate 用以进行身份询问。客户端可以返回一个 Proxy-Authorization 信息头用以验证。参见RFC 2617。 |
| **408** | **请求超时。**客户端没有在服务器预备等待的时间内完成一个请求的发送。客户端可以随时再次提交这一请求而无需进行任何更改。 |
| 409     | 由于和被请求的资源的当前状态之间存在冲突，请求无法完成。这个代码只允许用在这样的情况下才能被使用：用户被认为能够解决冲突，并且会重新提交新的请求。该响应应当包含足够的信息以便用户发现冲突的源头。 　　冲突通常发生于对 PUT 请求的处理中。例如，在采用版本检查的环境下，某次 PUT 提交的对特定资源的修改请求所附带的版本信息与之前的某个（第三方）请求向冲突，那么此时服务器就应该返回一个409错误，告知用户请求无法完成。此时，响应实体中很可能会包含两个冲突版本之间的差异比较，以便用户重新提交归并以后的新版本。 |
| 410     | 被请求的资源在服务器上已经不再可用，而且没有任何已知的转发地址。这样的状况应当被认为是永久性的。如果可能，拥有链接编辑功能的客户端应当在获得用户许可后删除所有指向这个地址的引用。如果服务器不知道或者无法确定这个状况是否是永久的，那么就应该使用404状态码。除非额外说明，否则这个响应是可缓存的。 　　410响应的目的主要是帮助网站管理员维护网站，通知用户该资源已经不再可用，并且服务器拥有者希望所有指向这个资源的远端连接也被删除。这类事件在限时、增值服务中很普遍。同样，410响应也被用于通知客户端在当前服务器站点上，原本属于某个个人的资源已经不再可用。当然，是否需要把所有永久不可用的资源标记为'410 Gone'，以及是否需要保持此标记多长时间，完全取决于服务器拥有者。 |
| 411     | 服务器拒绝在没有定义 Content-Length 头的情况下接受请求。在添加了表明请求消息体长度的有效 Content-Length 头之后，客户端可以再次提交该请求。 |
| 412     | 服务器在验证在请求的头字段中给出先决条件时，没能满足其中的一个或多个。这个状态码允许客户端在获取资源时在请求的元信息（请求头字段数据）中设置先决条件，以此避免该请求方法被应用到其希望的内容以外的资源上。 |
| 413     | 服务器拒绝处理当前请求，因为该请求提交的实体数据大小超过了服务器愿意或者能够处理的范围。此种情况下，服务器可以关闭连接以免客户端继续发送此请求。 　　如果这个状况是临时的，服务器应当返回一个 Retry-After 的响应头，以告知客户端可以在多少时间以后重新尝试。 |
| 414     | 请求的URI 长度超过了服务器能够解释的长度，因此服务器拒绝对该请求提供服务。这比较少见，通常的情况包括： 　　本应使用POST方法的表单提交变成了GET方法，导致查询字符串（Query String）过长。 　　重定向URI “黑洞”，例如每次重定向把旧的 URI 作为新的 URI 的一部分，导致在若干次重定向后 URI 超长。 　　客户端正在尝试利用某些服务器中存在的安全漏洞攻击服务器。这类服务器使用固定长度的缓冲读取或操作请求的 URI，当 GET 后的参数超过某个数值后，可能会产生缓冲区溢出，导致任意代码被执行[1]。没有此类漏洞的服务器，应当返回414状态码。 |
| 415     | 对于当前请求的方法和所请求的资源，请求中提交的实体并不是服务器中所支持的格式，因此请求被拒绝。 |
| 416     | 如果请求中包含了 Range 请求头，并且 Range 中指定的任何数据范围都与当前资源的可用范围不重合，同时请求中又没有定义 If-Range 请求头，那么服务器就应当返回416状态码。 　　假如 Range 使用的是字节范围，那么这种情况就是指请求指定的所有数据范围的首字节位置都超过了当前资源的长度。服务器也应当在返回416状态码的同时，包含一个 Content-Range 实体头，用以指明当前资源的长度。这个响应也被禁止使用 multipart/byteranges 作为其 Content-Type。 |
| 417     | 在请求头 Expect 中指定的预期内容无法被服务器满足，或者这个服务器是一个代理服务器，它有明显的证据证明在当前路由的下一个节点上，Expect 的内容无法被满足。 |
| 421     | 从当前客户端所在的IP地址到服务器的连接数超过了服务器许可的最大范围。通常，这里的IP地址指的是从服务器上看到的客户端地址（比如用户的网关或者代理服务器地址）。在这种情况下，连接数的计算可能涉及到不止一个终端用户。 |
| 422     | 从当前客户端所在的IP地址到服务器的连接数超过了服务器许可的最大范围。通常，这里的IP地址指的是从服务器上看到的客户端地址（比如用户的网关或者代理服务器地址）。在这种情况下，连接数的计算可能涉及到不止一个终端用户。 |
| 422     | 请求格式正确，但是由于含有语义错误，无法响应。（RFC 4918 WebDAV）423 Locked 　　当前资源被锁定。（RFC 4918 WebDAV） |
| 424     | 由于之前的某个请求发生的错误，导致当前请求失败，例如 PROPPATCH。（RFC 4918 WebDAV） |
| 425     | 在WebDav Advanced Collections 草案中定义，但是未出现在《WebDAV 顺序集协议》（RFC 3658）中。 |
| 426     | 客户端应当切换到TLS/1.0。（RFC 2817）                        |
| 449     | 由微软扩展，代表请求应当在执行完适当的操作后进行重试。       |
| **500** | **服务器遇到了一个未曾预料的状况，导致了它无法完成对请求的处理。一般来说，这个问题都会在服务器的程序码出错时出现。** |
| **501** | **服务器不支持当前请求所需要的某个功能。**当服务器无法识别请求的方法，并且无法支持其对任何资源的请求。 |
| **502** | **作为网关或者代理工作的服务器尝试执行请求时，从上游服务器接收到无效的响应。** |
| **503** | **由于临时的服务器维护或者过载，服务器当前无法处理请求。**这个状况是临时的，并且将在一段时间以后恢复。如果能够预计延迟时间，那么响应中可以包含一个 Retry-After 头用以标明这个延迟时间。如果没有给出这个 Retry-After 信息，那么客户端应当以处理500响应的方式处理它。 　　注意：503状态码的存在并不意味着服务器在过载的时候必须使用它。某些服务器只不过是希望拒绝客户端的连接。 |
| 504     | 作为网关或者代理工作的服务器尝试执行请求时，未能及时从上游服务器（URI标识出的服务器，例如HTTP、FTP、LDAP）或者辅助服务器（例如DNS）收到响应。 　　注意：某些代理服务器在DNS查询超时时会返回400或者500错误 |
| **505** | **服务器不支持，或者拒绝支持在请求中使用的 HTTP 版本。**这暗示着服务器不能或不愿使用与客户端相同的版本。响应中应当包含一个描述了为何版本不被支持以及服务器支持哪些协议的实体。 |
| 506     | 由《透明内容协商协议》（RFC 2295）扩展，代表服务器存在内部配置错误：被请求的协商变元资源被配置为在透明内容协商中使用自己，因此在一个协商处理中不是一个合适的重点。 |
| 507     | 服务器无法存储完成请求所必须的内容。这个状况被认为是临时的。WebDAV (RFC 4918) |
| 509     | 服务器达到带宽限制。这不是一个官方的状态码，但是仍被广泛使用。 |
| 510     | 获取资源所需要的策略并没有没满足。（RFC 2774）               |



### http和https的区别？

HTTP 属于超文本传输协议，用来在 Internet 上传送超文本，而 HTTPS 为安全超文本传输协议，在 HTTPS 基础上拥有更强的安全性，简单来说 HTTPS 是 HTTP 的安全版，是**使用 TLS/SSL （位于应用层和运输层之间）加密的 HTTP 协议**。

1. HTTP的默认端口号是80，HTTPS的默认端口号是443；

2. HTTP使用明文传输，HTTPS使用密文传输；

3. HTTPS在HTTP的基础上多加了一个SSL，安全套接字层；在开始数据传输之前，客户端与服务端需要进行双向身份验证，以及进行压缩算法、加密算法的协商；

4. 在决定了加密算法之后，需要交换密钥；具体过程为：

   ①客户端随机生成一段字符串，然后使用服务端的公钥进行加密，然后传输给服务端；

   ②服务端收到之后使用自己的私钥进行解密，这个字符串就是数据传输使用的密钥；

   ③交换密钥的阶段是非对称加密，进行数据传输时时候的是对称加密；

   一般使用的**非对称加密**的密钥交换算法是**RSA**, **数字签名摘要算法一般是SHA或者MD5** , 加密传输数据的**对称加密算法是DES**。

5. **SSL使用序列号来保护通讯方免受报文重放攻击。**这个序列号被加密后作为数据包的负载。在整个SSL握手中,都有一个唯一的随机数来标记SSL握手。 防止了攻击者嗅探整个登录过程，获取到加密的登录数据之后，不对数据进行解密, 而直接重传登录数据包的攻击手法。





### 有趣的智力题

1. 有32块石头，一个天平，石头重量不一，多少次找到最重的那一块石头？

   应该是31次，没什么捷径， 就一个一个量；

2. 刚找出来最重的那一块，那第二重那一块还要不要天平？多少次能找到？

   答案是4次。**这里在第1题我们建立了一棵树，可以想象一下32强晋级赛**；

   ![](img/zlt1.jpg)

   例如，这里有4块石头，我们比较了3次得到了1是最重的；**这个时候3就是第二重的吗？**不是的，3有可能是第三重的，因为2有可能是第二重的；因此**所有跟1比较过的石头和3这块石头加一起，**选出其中最重的石头；在右子树里面，3肯定是最重的；在左子树里面，第二重的石头肯定跟1比较过；因此32块石头的树深度为5，跟1比较过的有4块，加上右子树的顶端，5块石头，比较4次就能找到第二重的；

3. **一种流行病患病概率是1%，有一种检测试纸，检测的准确率是99%，我现在试纸检测阳性了，请问我患病的概率有多大？**

   ![](img/bys.png)

   这是一道贝叶斯估计的题目（**字节是不是就喜欢智力题**）：

   ![](img/zlt2.jpg)

   太有意思了；
   
4. **等比数列求和公式的推导**

   真的扯淡了，这都问：

   ![](img/dbslqh.png)

   这里将Sn乘q，然后作差，右边只剩下an-a（n+1），左边是（1-q）Sn，所以就求出来了；

5. 有一个白色袋子一个黑色袋子，白色袋子里面有7个红球3个蓝球，黑色袋子里面有3个红球7个蓝球；**随机选择一个袋子，随机从里面抽一个球，并且放回**，问拿到的6个红球4个篮球都是黑色袋子里面取得的概率？

   ![](img/glt1.jpg)







### 在C++中，声明 int const** const * const x 表示x是什么类型？

1. 最里层是一个\* const x，这是一个const 指针；
2. 外面的一层\* const（\* const x），括号里面在①里面说过了，是一个const指针，所以这里还是一个const 指针；
3. 最外层int const \*（\* const（\* const x））这里的int和const位置不重要，都是指这个int是const的；然后这里就是一个普通指针；
4. 综上所述，这是一个**const指针，指向一个const指针，指向一个普通指针，指向一个const int**；







### select、poll和epoll的区别[资料](https://www.cnblogs.com/aspirant/p/9166944.html)

1. select仅支持固定数量的fd，poll和epoll均不收fd的限制，poll使用链表存储，epoll使用一个fd来管理其他所有的fd；
2. select和poll均仅知道管理中的fd有事件发生，但是均无法确定是哪一个事件，因此要通过**O（n）的轮询来检查每一个fd；**epoll由于使用了回调函数的机制，每一个fd会自主调用回调函数，以此实现**O（1）的fd返回**；但是注意，**在所有fd都很活跃或者本身fd就很少的情况下，epoll可能不如select和poll；**
3. select和poll进行轮询时需要从用户态切换到内核态，同时需要拷贝所有的fd，因此有一定的开销；epoll则通过共享内存的方式避免了拷贝，因此效率较高；
4. 在实现上，epoll的epoll_wait其实就是检查消息链表是否为空，不为空则返回；每一个fd的回调函数就是收到相应事件响应的时候将自己挂在消息链表中；





### 消息中间件有什么作用？

### **消息中间件可以解决什么问题？**

　1. **削峰** 诸如双十一零点时淘宝的数据量陡增，服务器会承担极大的压力。我们不能以在数据量最大的时候所需要的资源数来配置资源，那样除了在某一段时间或某一刻数据量非常大，其他时间数据量都很小，会浪费很多资源。

　2. **异步处理** 为了实现快速响应用户，我们可以先完成必须的工作，而不必等待所有的工作做完。通常像通过邮件发送用户手册的任务可以稍后再做。

　3. **解耦**　多个系统为了减少相互依赖性，避免一个系统的改动引起其他系统的改动，可以使用消息中间件来达到目的。那么为什么使用消息中间件可以起到解耦的作用呢？
　　我们首先需要知道什么是耦合，耦合是指系统之间的依赖，比如A系统以来与B系统提供的接口。耦合分为7类，我们最常见的是数据耦合和标记耦合，耦合的7种种类可以参考[图解7种耦合关系](https://yanhaijing.com/program/2016/09/01/about-coupling/)
　　使用消息中间件作为中介之后，调用方和被调用方的依赖情况发生了一下的变化：
　　　a. 调用方不需要知道被调用方的接口名和参数，只需要将数据发送给消息中间件。
　　　b. 被调用系统参数的错误或者进程挂掉不会是调用方产生错误。

也就是调用方和被调用方的依赖关系装换为了调用方与消息中间件，消息中间件和被调用方的依赖关系。但是消息中间件的接口通常不会变化并且接口比较统一，所以耦合度就降低了。





### IP数据报的首部有什么？HTTP的请求报文和响应报文呢？

![](img/ipsb.jpg)

![](img/httpqq.jpg)

![](img/httpxy.jpg)





### sizeof和strlen的区别

1. sizeof()是运算符，strlen()是库函数

2. sizeof()在编译时计算好了，strlen()在运行时计算

3. sizeof()计算出对象使用的最大字节数，strlen()计算字符串的实际长度

   对于一个字符串“hello”，sizeof输出6，strlen输出5；因为sizeof把结尾'\0'也统计了，但是strlen不会统计；

4. sizeof()的参数类型多样化（数组，指针，对象，函数都可以），strlen()的参数必须是字符型指针（传入数组时自动退化为指针）





### 如何使用rand5生成rand7

关键的点在于等概率生成。可以先考虑，到底如何才能等概率生成rand7呢？**就是rand（7\*n）**，也就是说我们先rand21，然后对7取模即可；rand5可以生成1、2、3、4、5，全部减去1然后乘以5，就可以得到0、10、15、20、25，**我们这里截取0~20**，其他数字就再获取一遍；然后先加7再对7取模即可；

```c++
//题目本意：利用rand5()写一个函数生成等概率的1,2,3,4,5,6,7
int rand7(){
	int i = (rand5()-1)*5+rand5(); //等概率生成0-24
	while(i>20){
		i = (rand5()-1)*5+rand5();
	}//筛选0-20
	return i%7+1;
}
```





### 描述一下redis的模型

redis是一个单线程模型，但是redis是支持**并发**的；其具体的实现是一个**IO多路复用+文件分发器+事件处理器；**

![](img/redis50.jpg)

多个客户端可以连接到redis服务器，**请求连接本身就是一个事件**；redis从自己的epoll上面的监听socket收到一个连接请求；然后将其**放入文件分发器队列**，文件分发器队列根据事件类型选择对应的事件处理器；**这个文件分发器+事件处理器都是单线程的**，所以说redis是一个单线程模型；因此对于多个客户端的请求，都是串行执行的；

redis的并发解决方案是：**单线程多进程**；redis还是使用单线程模型，但是我们可以运行多个redis实例啊；例如CPU有四核，那我们运行四个redis不就行了吗；

**那么为什么redis的效率这么高？**

1. redis的读写是纯内存操作，没有硬盘IO；
2. 单线程没有线程切换时产生的开销；也不用考虑竞态条件；
3. redis使用多路IO复用技术，将读、写、关闭、连接都处理成事件；

**redis如何优化？**

redis的瓶颈不在于CPU，主要在于**内存和网络**；内存不够买就行了，但是网络是硬伤；首先来看看网络IO的耗时公式：

**网络IO主要延时**： 服务器响应延时 + 带宽限制 + 网络延时 + 跳转路由延时 + 本地接收延时 决定。（一般为几十到几千毫秒，受环境干扰极大）

其实在redis4就已经有**多线程**负责后台删除对象等操作；但是不得不说，网络IO还是占了redis很大一部分的时间；但是由于网络IO这部分操作不会影响数据库里面的数据，因此在redis6里面就**使用多线程来负责网络数据的读写和命令解析**，真正的数据库读写还是使用单线程来实现；





### redis和memcache的区别

1. 支持的数据类型不同，redis和memcache都支持key-value，但同时redis还支持字符串、集合、哈希表、有序集合；

2. redis支持rdb和aof两种数据持久化方案；但是memcache不支持数据的持久化；出现故障之后memcache数据就会全部丢失，如果考虑数据的持久化就使用redis；

3. redis支持使用虚拟内存，所以redis能使用的空间大于内存；memcache能使用的空间就是本身的内存空间；

4. redis使用主从模式实现分布式存储，memcache可以使用一致性hash做分布式存储；

   科普：[一致性哈希](https://www.jianshu.com/p/528ce5cd7e8f)

   一般情况下，我们有5台服务器，对于一个文件a.png，我们可以hash（a.png）%6来获取这个文件在哪一个服务器上；但是当有一个服务器宕机或者有新的服务器加入的时候，就需要对所有数据rehash，这个开销是在太大了；因此就引入了一致性hash

   这里的取模不是服务器的个数，而是**2^32**，所以这个一致性hash可以支持**2^32**台主机；

   我们用一个圆来表示这个hash空间，最顶部是0，然后顺时针依次是1、2、....；

   然后我们将每一个服务器都hash一下，这个参数可以用主机的名称啊，MAC地址等等，**每一个服务器就会在这个圆上的某一个点**；

   当我们**查找a.png时**，就hash一下，到一个点，**然后顺时针遇到的第一个服务器**就是我们的目标服务器；如下图

   ![](img/yzxhx.png)

   **节点的新增和删除**

   如果有服务器宕机或者新增了服务器，也只是影响了小部分的数据查询，后续再重新复制一波就行了；

   **数据倾斜**

   当服务器数量很少，可能百分之90的数据会放到一台机器上；我们可以使用多个虚拟节点来不表示同一台机器，**这样每一台机器在这个圆上就有很多个节点**；

5. memcache对数据的value要求小于1M，但是redis可以存放512M的value；

6. redis是单线程模型，所以使用单核；memcache是多线程的，可以使用多核；所以当读写数据量大的时候，memcache会比较快；

   memcache如何同步？

   使用CAS（Check and Set）保证数据一致性，使用**乐观锁**实现；在memcache对数据进行读写的时候先取得当前系统的版本号，在最终写入数据库的时候再取一次版本号，如果一致则写入，不一致则放弃操作；





### 介绍一下RPC的流程

RPC（Remote Procedure Call）远端过程调用，**使得调用另一台主机上的函数就像调用本地的函数一样方便；**一般是采用C\S模型来实现；

![](E:/C++pythonlearning/神秘资料/面向工作学习/必读书目/InterviewKnowledge/secret/学习笔记/img/rpc1.png)

在RPC调用中，**参数存放的堆栈地址，调用函数的地址等都是不同的；因此必须将其经过编码转换为可传输的格式，在服务方进行解码然后再进行调用；这里trpc的实现是使用一个map，key为方法名，value为方法的地址，因此可以通过函数名直接调用；**

一次完整的RPC调用流程（**同步调用情况下**）如下：

1）服务消费方（client）调用以本地调用方式调用服务；

2）client stub接收到调用后负责将方法、参数等组装成能够进行网络传输的消息体；

3）client stub找到服务地址，并将消息发送到服务端；

4）server stub收到消息后进行解码；

5）server stub根据解码结果调用本地的服务；

6）本地服务执行并将结果返回给server stub；

7）server stub将返回结果打包成消息并发送至消费方；

8）client stub接收到消息，并进行解码；

9）服务消费方得到最终结果。

由于一般这种都是并发的操作，因此我们需要stub作为proxy，进行**负载均衡、容灾容错**；

此外，还需要一个服务注册中心，例如使用zookeeper作为服务注册中心：

1. 服务提供方提供某服务的时候，需要在zk上进行注册；使用zk类似文档的存储结构可以将不同服务中的同名方法区别开来；**在对应服务的目录下存在服务器的ip地址，方便调用；**

2. 同时可以设置一个标志unavailable表示该服务不可用，实现延迟上线、优雅下线；

   **延迟上线：**server 向注册中心unavailableServer 注册，状态unavailable，此时整个服务处于**启动**状态，**不对外提供服务**，在服务验证通过，**预热**完毕，此时打开心跳开关**提供服务**。

   **优雅关机：**对 server 方进行**维护升级**，**直接关闭影响**到客户端的**请求**。先切断流量，再进行 server 下线。做法：**先关闭心跳开关**，**客户端感知**停止调用后，再**关闭服务**进程。

3. 心跳检测：

   用于应对非正常下线的情况，每30s访问一次服务，如果某个服务3次没有应答，自动下线该服务；**客户端还可以通过订阅功能感知服务的上线和下线；**





### 缓存穿透、缓存血崩

1. **缓存穿透**

   首先要知道，我们查询数据的时候会先在缓存中查询，没有命中才会去数据库查，同时更新到缓存；存在一种情况，如果**某条数据在数据库中根本不存在**，那缓存中永远也不可能有这条数据，因此这种查询每次都会到数据库去查，会对数据库造成很大的压力；

   解决方法：

   ①在不存在的字段预设一个值，例如null；那么返回null的时候我们就知道不存在了，我们可以捕捉这个值来决定怎么做，或者存在缓存了，查缓存查到这个值就知道这个数据不存在了；

   ②**布隆过滤器**

   布隆过滤器实际上是一个**很长的二进制向量（每一位不是0就是1）和一系列随机映射函数**。布隆过滤器可以**用于检索一个元素是否在一个集合中**。它的优点是空间效率和查询时间都比一般的算法要好的多，**缺点是有一定的误识别率和删除困难**。

   **如何使用**

   对于任意一个数据，我们可以通过hash（数据）得到一个值n，用这个值n来表示布隆过滤器里面的第n位，我们将这一位置1；但是考虑到判断准确率的问题，一般会使用m个hash，这样，**一个数据会使得布隆过滤器m为置1**；

   当我们查找的时候，同样使用这m个hash，然后取检查布隆过滤器里面是否都是1；

   **注意：**主要有一个不是1，**数据肯定不存在**；全部都是1，**数据还是有可能不存在**；所以布隆过滤器肯定是不准的；

   **优点**

   1. 相比于其他数据结构，布隆过滤器的**内存需求巨低**，插入和查询都是O（1）；
   2. 数据安全，布隆过滤器**不保存任何数据**，只标记该数据是否存在；

   **缺点**

   1. 有一定的**误判率**，随着数据增加，误判率会上升；解决方法为**建立一个白名单**，用来标记必然存在的数据；
   2. **删除困难**；因为即使命中了，该数据也不一定存在于布隆过滤器里面，这时候删除那不就出事儿了？

2. **缓存雪崩**

   即缓存失效，一般是因为缓存中的数据**全部同时过期**，此时的查询全部都不会命中，因此全部都到数据库去查询，压力巨大；还有一种情况是缓存挂了；

   解决方法：

   ①如果是因为同时过期，可以设置过期时间的时候加上一个随机数，这样就不会同时过期了；

   ②缓存挂了其实不太可能，像redis的主从结构，哨兵等都使得redis高可用；





### 网页URL的去重，垃圾邮件的判别，集合重复元素的判别，查询加速（比如基于key-value的存储系统）

如果一个黑名单网站包含100亿个黑名单网页，每个网页最多占64B，设计一个系统，判断当前的URL是否在这个黑名单当中，要求额外空间不超过30GB，允许误差率为万分之一。

**如何计算在特定误判率下的bitarray的长度呢？**

![](img/bloom.png)

通过计算，上面这个黑名单系统只需要25GB的空间就可以做到；







### Go中make（chan int）和make（chan int，1）有什么区别？

1. make（chan int）

   这是一个**No Buffer Channel**，也就是如果向这个管道send数据，**会一直阻塞直到有人receive；**也就是说，向下面这种：

   ```go
   package main
   
   import "fmt"
   
   func main() {
       var c = make(chan int)
       var a string
   
       go func() {
           a = "hello world"
           <-c
       }()
   
       c <- 0
       fmt.Println(a)
   }
   ```

   这里打印的a肯定是hello world，因为**c<-0这个向管道发送一个0的操作**会被阻塞，直到**<-c从管道中读取**，这就是无缓存的chan；

2. make（chan int，1）

   这个是**Buffer Channel**，这个管道自带缓存，**缓存大小为1\*int，也就是可以容纳一个int**；这种情况下我们send数据进管道会立刻返回，无需等待；所以上面的操作a经常会打印出来是空的；





